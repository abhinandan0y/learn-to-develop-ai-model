{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33deb4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.8.0\n",
      "torch version: 2.2.2\n",
      "tiktoken version: 0.4.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "import matplotlib\n",
    "import tiktoken\n",
    "import torch\n",
    "\n",
    "print(\"matplotlib version:\", version(\"matplotlib\"))\n",
    "print(\"torch version:\", version(\"torch\"))\n",
    "print(\"tiktoken version:\", version(\"tiktoken\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dbd9b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,    # Vocabulary size\n",
    "    \"context_length\": 1024, # Context length\n",
    "    \"emb_dim\": 768,         # Embedding dimension\n",
    "    \"n_heads\": 12,          # Number of attention heads\n",
    "    \"n_layers\": 12,         # Number of layers\n",
    "    \"drop_rate\": 0.1,       # Dropout rate\n",
    "    \"qkv_bias\": False       # Query-Key-Value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1944ae2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class DummyGPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        \n",
    "        # Use a placeholder for TransformerBlock\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[DummyTransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        \n",
    "        # Use a placeholder for LayerNorm\n",
    "        self.final_norm = DummyLayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class DummyTransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        # A simple placeholder\n",
    "    def forward(self, x):\n",
    "        # This block does nothing and just returns its input.\n",
    "        return x\n",
    "\n",
    "\n",
    "class DummyLayerNorm(nn.Module):\n",
    "    def __init__(self, normalized_shape, eps=1e-5):\n",
    "        super().__init__()\n",
    "        # The parameters here are just to mimic the LayerNorm interface.\n",
    "    def forward(self, x):\n",
    "        # This layer does nothing and just returns its input.\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e751ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "batch = []\n",
    "\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day holds a\"\n",
    "\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "batch = torch.stack(batch, dim=0)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72088fa1",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (130587490.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[5], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    Output shape: torch.Size([2, 4, 50257])\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = DummyGPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "logits = model(batch)\n",
    "print(\"Output shape:\", logits.shape)\n",
    "print(logits)\n",
    "Output shape: torch.Size([2, 4, 50257])\n",
    "tensor([[[-1.2034,  0.3201, -0.7130,  ..., -1.5548, -0.2390, -0.4667],\n",
    "         [-0.1192,  0.4539, -0.4432,  ...,  0.2392,  1.3469,  1.2430],\n",
    "         [ 0.5307,  1.6720, -0.4695,  ...,  1.1966,  0.0111,  0.5835],\n",
    "         [ 0.0139,  1.6754, -0.3388,  ...,  1.1586, -0.0435, -1.0400]],\n",
    "\n",
    "        [[-1.0908,  0.1798, -0.9484,  ..., -1.6047,  0.2439, -0.4530],\n",
    "         [-0.7860,  0.5581, -0.0610,  ...,  0.4835, -0.0077,  1.6621],\n",
    "         [ 0.3567,  1.2698, -0.6398,  ..., -0.0162, -0.1296,  0.3717],\n",
    "         [-0.2407, -0.7349, -0.5102,  ...,  2.0057, -0.3694,  0.1814]]],\n",
    "       grad_fn=<UnsafeViewBackward0>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36cc87fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2260, 0.3470, 0.0000, 0.2216, 0.0000, 0.0000],\n",
      "        [0.2133, 0.2394, 0.0000, 0.5198, 0.3297, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "# create 2 training examples with 5 dimensions (features) each\n",
    "batch_example = torch.randn(2, 5) \n",
    "\n",
    "layer = nn.Sequential(nn.Linear(5, 6), nn.ReLU())\n",
    "out = layer(batch_example)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "453eef62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[0.1324],\n",
      "        [0.2170]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[0.0231],\n",
      "        [0.0398]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mean = out.mean(dim=-1, keepdim=True)\n",
    "var = out.var(dim=-1, keepdim=True)\n",
    "\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5d2671d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized layer outputs:\n",
      " tensor([[ 0.6159,  1.4126, -0.8719,  0.5872, -0.8719, -0.8719],\n",
      "        [-0.0189,  0.1121, -1.0876,  1.5173,  0.5647, -1.0876]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "Mean:\n",
      " tensor([[9.9341e-09],\n",
      "        [1.9868e-08]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out_norm = (out - mean) / torch.sqrt(var)\n",
    "print(\"Normalized layer outputs:\\n\", out_norm)\n",
    "\n",
    "mean = out_norm.mean(dim=-1, keepdim=True)\n",
    "var = out_norm.var(dim=-1, keepdim=True)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2b4e490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[    0.0000],\n",
      "        [    0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(sci_mode=False)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68d2ac9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf65d5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ln = LayerNorm(emb_dim=5)\n",
    "out_ln = ln(batch_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ca7e306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[    -0.0000],\n",
      "        [     0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mean = out_ln.mean(dim=-1, keepdim=True)\n",
    "var = out_ln.var(dim=-1, unbiased=False, keepdim=True)\n",
    "\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "faa796cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) * \n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c9467a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gelu, relu = GELU(), nn.ReLU()\n",
    "\n",
    "# Some sample data\n",
    "x = torch.linspace(-3, 3, 100)\n",
    "y_gelu, y_relu = gelu(x), relu(x)\n",
    "\n",
    "plt.figure(figsize=(8, 3))\n",
    "for i, (y, label) in enumerate(zip([y_gelu, y_relu], [\"GELU\", \"ReLU\"]), 1):\n",
    "    plt.subplot(1, 2, i)\n",
    "    plt.plot(x, y)\n",
    "    plt.title(f\"{label} activation function\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(f\"{label}(x)\")\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb3ab535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n"
     ]
    }
   ],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
    "            GELU(),\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "print(GPT_CONFIG_124M[\"emb_dim\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00936c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 768])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffn = FeedForward(GPT_CONFIG_124M)\n",
    "\n",
    "# input shape: [batch_size, num_token, emb_size]\n",
    "x = torch.rand(2, 3, 768) \n",
    "out = ffn(x)\n",
    "print(out.shape)\n",
    "torch.Size([2, 3, 768])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de07f82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleDeepNeuralNetwork(nn.Module):\n",
    "    def __init__(self, layer_sizes, use_shortcut):\n",
    "        super().__init__()\n",
    "        self.use_shortcut = use_shortcut\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Sequential(nn.Linear(layer_sizes[0], layer_sizes[1]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[1], layer_sizes[2]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[2], layer_sizes[3]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[3], layer_sizes[4]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[4], layer_sizes[5]), GELU())\n",
    "        ])\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            # Compute the output of the current layer\n",
    "            layer_output = layer(x)\n",
    "            # Check if shortcut can be applied\n",
    "            if self.use_shortcut and x.shape == layer_output.shape:\n",
    "                x = x + layer_output\n",
    "            else:\n",
    "                x = layer_output\n",
    "        return x\n",
    "\n",
    "\n",
    "def print_gradients(model, x):\n",
    "    # Forward pass\n",
    "    output = model(x)\n",
    "    target = torch.tensor([[0.]])\n",
    "    # Calculate loss based on how close the target\n",
    "    # and output are\n",
    "    loss = nn.MSELoss()\n",
    "    loss = loss(output, target)    \n",
    "    # Backward pass to calculate the gradients\n",
    "    loss.backward()\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            # Print the mean absolute gradient of the weights\n",
    "            print(f\"{name} has gradient mean of {param.grad.abs().mean().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "def04692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.00020173584925942123\n",
      "layers.1.0.weight has gradient mean of 0.00012011159560643137\n",
      "layers.2.0.weight has gradient mean of 0.0007152040489017963\n",
      "layers.3.0.weight has gradient mean of 0.0013988736318424344\n",
      "layers.4.0.weight has gradient mean of 0.005049645435065031\n"
     ]
    }
   ],
   "source": [
    "layer_sizes = [3, 3, 3, 3, 3, 1]  \n",
    "\n",
    "sample_input = torch.tensor([[1., 0., -1.]])\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model_without_shortcut = ExampleDeepNeuralNetwork(\n",
    "    layer_sizes, use_shortcut=False\n",
    ")\n",
    "print_gradients(model_without_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e85db449",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "model_with_shortcut = ExampleDeepNeuralNetwork(\n",
    "    layer_sizes, use_shortcut=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f23d4b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#**MultiHeadAttention** method\n",
    "import tiktoken\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "        # Tokenize the entire text\n",
    "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "\n",
    "\n",
    "def create_dataloader_v1(txt, batch_size=4, max_length=256,\n",
    "                         stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
    "    # Initialize the tokenizer\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    # Create dataset\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "    # Create dataloader\n",
    "    dataloader = DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last, num_workers=0)\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert d_out % num_heads == 0, \"d_out must be divisible by num_heads\"\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads  # Reduce the projection dim to match desired output dim\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "        keys = self.W_key(x)  # Shape: (b, num_tokens, d_out)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
    "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
    "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
    "        # Original mask truncated to the number of tokens and converted to boolean\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "        # Use the mask to fill attention scores\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
    "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec)  # optional projection\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b4b58ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from previous_chapters import **MultiHeadAttention**\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            num_heads=cfg[\"n_heads\"], \n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"])\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "    def forward(self, x):\n",
    "        # Shortcut connection for attention block\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "        # Shortcut connection for feed forward block\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb589eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4, 768])\n",
      "Output shape: torch.Size([2, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "x = torch.rand(2, 4, 768)  # Shape: [batch_size, num_tokens, emb_dim]\n",
    "block = TransformerBlock(GPT_CONFIG_124M)\n",
    "output = block(x)\n",
    "\n",
    "print(\"Input shape:\", x.shape)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f779f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        \n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        \n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99565d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch:\n",
      " tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n",
      "\n",
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[ 0.1381,  0.0077, -0.1963,  ..., -0.0222, -0.1060,  0.1717],\n",
      "         [ 0.3865, -0.8408, -0.6564,  ..., -0.5163,  0.2369, -0.3357],\n",
      "         [ 0.6989, -0.1829, -0.1631,  ...,  0.1472, -0.6504, -0.0056],\n",
      "         [-0.4290,  0.1669, -0.1258,  ...,  1.1579,  0.5303, -0.5549]],\n",
      "\n",
      "        [[ 0.1094, -0.2894, -0.1467,  ..., -0.0557,  0.2911, -0.2824],\n",
      "         [ 0.0882, -0.3552, -0.3527,  ...,  1.2930,  0.0053,  0.1898],\n",
      "         [ 0.6091,  0.4702, -0.4094,  ...,  0.7688,  0.3787, -0.1974],\n",
      "         [-0.0612, -0.0737,  0.4751,  ...,  1.2463, -0.3834,  0.0609]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "out = model(batch)\n",
    "print(\"Input batch:\\n\", batch)\n",
    "print(\"\\nOutput shape:\", out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "40bf23e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 163,009,536\n"
     ]
    }
   ],
   "source": [
    "#Now We will train this model :\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1021a6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token embedding layer shape: torch.Size([50257, 768])\n",
      "Output layer shape: torch.Size([50257, 768])\n"
     ]
    }
   ],
   "source": [
    "print(\"Token embedding layer shape:\", model.tok_emb.weight.shape)\n",
    "print(\"Output layer shape:\", model.out_head.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9458db23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters considering weight tying: 124,412,160\n"
     ]
    }
   ],
   "source": [
    "total_params_gpt2 =  total_params - sum(p.numel() for p in model.out_head.parameters())\n",
    "print(f\"Number of trainable parameters considering weight tying: {total_params_gpt2:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4eecfc21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of the model: 621.83 MB\n"
     ]
    }
   ],
   "source": [
    "total_size_bytes = total_params * 4\n",
    "\n",
    "# Convert to megabytes\n",
    "total_size_mb = total_size_bytes / (1024 * 1024)\n",
    "\n",
    "print(f\"Total size of the model: {total_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "336d5490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.8.0\n",
      "numpy version: 1.25.2\n",
      "tiktoken version: 0.4.0\n",
      "torch version: 2.2.2\n",
      "tensorflow version: 2.16.1\n"
     ]
    }
   ],
   "source": [
    "#Pretraining on Unlabeled Data\n",
    "\n",
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"matplotlib\", \n",
    "        \"numpy\", \n",
    "        \"tiktoken\", \n",
    "        \"torch\",\n",
    "        \"tensorflow\" # For OpenAI's pretrained weights\n",
    "       ]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f8916cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating generative text models\n",
    "import torch\n",
    "#from previous_chapters import GPTModel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e5d2cb2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "                      IN\n",
      "==================================================\n",
      "\n",
      "Input text: Hello, I am\n",
      "Encoded input text: [15496, 11, 314, 716]\n",
      "encoded_tensor.shape: torch.Size([1, 4])\n",
      "\n",
      "\n",
      "==================================================\n",
      "                      OUT\n",
      "==================================================\n",
      "\n",
      "Output: tensor([[15496,    11,   314,   716, 27018, 24086, 47843, 30961, 42348,  7267,\n",
      "         49706, 43231, 47062, 34657]])\n",
      "Output length: 14\n",
      "Output text: Hello, I am Featureiman Byeswickattribute argue logger Normandy Compton analogous\n"
     ]
    }
   ],
   "source": [
    "#GPTModel\n",
    "\n",
    "import tiktoken\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "#####################################\n",
    "# Chapter 2\n",
    "#####################################\n",
    "\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride, num_workers=0):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "        # Tokenize the entire text\n",
    "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "\n",
    "\n",
    "def create_dataloader_v1(txt, batch_size=4, max_length=256,\n",
    "                         stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
    "    # Initialize the tokenizer\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    # Create dataset\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "    # Create dataloader\n",
    "    dataloader = DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last)\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "#####################################\n",
    "# Chapter 3\n",
    "#####################################\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert d_out % num_heads == 0, \"d_out must be divisible by num_heads\"\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads  # Reduce the projection dim to match desired output dim\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\"mask\", torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "        keys = self.W_key(x)  # Shape: (b, num_tokens, d_out)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
    "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
    "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
    "        # Original mask truncated to the number of tokens and converted to boolean\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "        # Use the mask to fill attention scores\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
    "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec)  # optional projection\n",
    "        return context_vec\n",
    "\n",
    "\n",
    "#####################################\n",
    "# Chapter 4\n",
    "#####################################\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift\n",
    "\n",
    "\n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
    "            GELU(),\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            num_heads=cfg[\"n_heads\"],\n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"])\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "    def forward(self, x):\n",
    "        # Shortcut connection for attention block\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)   # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "        # Shortcut connection for feed-forward block\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "        return x\n",
    "\n",
    "\n",
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    # idx is (B, T) array of indices in the current context\n",
    "    for _ in range(max_new_tokens):\n",
    "        # Crop current context if it exceeds the supported context size\n",
    "        # E.g., if LLM supports only 5 tokens, and the context size is 10\n",
    "        # then only the last 5 tokens are used as context\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        # Get the predictions\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        # Focus only on the last time step\n",
    "        # (batch, n_token, vocab_size) becomes (batch, vocab_size)\n",
    "        logits = logits[:, -1, :]\n",
    "        # Get the idx of the vocab entry with the highest logits value\n",
    "        idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch, 1)\n",
    "        # Append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
    "    return idx\n",
    "\n",
    "\n",
    "def main():\n",
    "    GPT_CONFIG_124M = {\n",
    "        \"vocab_size\": 50257,     # Vocabulary size\n",
    "        \"context_length\": 1024,  # Context length\n",
    "        \"emb_dim\": 768,          # Embedding dimension\n",
    "        \"n_heads\": 12,           # Number of attention heads\n",
    "        \"n_layers\": 12,          # Number of layers\n",
    "        \"drop_rate\": 0.1,        # Dropout rate\n",
    "        \"qkv_bias\": False        # Query-Key-Value bias\n",
    "    }\n",
    "    torch.manual_seed(123)\n",
    "    model = GPTModel(GPT_CONFIG_124M)\n",
    "    model.eval()  # disable dropout\n",
    "    start_context = \"Hello, I am\"\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    encoded = tokenizer.encode(start_context)\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "    print(f\"\\n{50*'='}\\n{22*' '}IN\\n{50*'='}\")\n",
    "    print(\"\\nInput text:\", start_context)\n",
    "    print(\"Encoded input text:\", encoded)\n",
    "    print(\"encoded_tensor.shape:\", encoded_tensor.shape)\n",
    "    out = generate_text_simple(\n",
    "        model=model,\n",
    "        idx=encoded_tensor,\n",
    "        max_new_tokens=10,\n",
    "        context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    "    )\n",
    "    decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
    "    print(f\"\\n\\n{50*'='}\\n{22*' '}OUT\\n{50*'='}\")\n",
    "    print(\"\\nOutput:\", out)\n",
    "    print(\"Output length:\", len(out[0]))\n",
    "    print(\"Output text:\", decoded_text)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2c9340aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#from previous_chapters import GPTModel\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # Vocabulary size\n",
    "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 768,        # Embedding dimension\n",
    "    \"n_heads\": 12,         # Number of attention heads\n",
    "    \"n_layers\": 12,        # Number of layers\n",
    "    \"drop_rate\": 0.1,      # Dropout rate\n",
    "    \"qkv_bias\": False      # Query-key-value bias\n",
    "}\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval();  # Disable dropout during inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "254b1f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic wasn refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "#from previous_chapters import generate_text_simple\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dc1e41e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the text generation loss: cross entropy, and perplexity\n",
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                       [40,    1107, 588]])   #  \"I really like\"]\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
    "                        [1107,  588, 11311]]) #  \" really like chocolate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ec899dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "\n",
    "probas = torch.softmax(logits, dim=-1) # Probability of each token in vocabulary\n",
    "print(probas.shape) # Shape: (batch_size, num_tokens, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e39c1a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b630544b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([    0.0001,     0.0000,     0.0000])\n",
      "Text 2: tensor([    0.0000,     0.0001,     0.0000])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b9f00fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n",
      "tensor(-10.7940)\n",
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "#Compute logarithm of all token probabilities\n",
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)\n",
    "#tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n",
    "#Calculate the average probability for each token\n",
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)\n",
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f1a09d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "# Logits have shape (batch_size, num_tokens, vocab_size)\n",
    "print(\"Logits shape:\", logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8095ce31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(\"Targets shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "30836ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8c083acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9cef118c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(48725.8203)\n"
     ]
    }
   ],
   "source": [
    "perplexity = torch.exp(loss)\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4d41748b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the training and validation set losses\n",
    "\n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "#file_path = \"the-verdict.txt\"\n",
    "#url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
    "\n",
    "#if not os.path.exists(file_path):\n",
    "#    with urllib.request.urlopen(url) as response:\n",
    "#        text_data = response.read().decode('utf-8')\n",
    "#    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "#        file.write(text_data)\n",
    "#else:\n",
    "#    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "#        text_data = file.read()\n",
    "\n",
    "#file_path = \"train_on_geeta.txt\"\n",
    "file_path = \"/home/bioinfo2/Downloads/myfiles/doc/WhatsAppChat.txt\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "         text_data = file.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "69ad8ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " U peeps don't miss me \n",
      " \n",
      "\n",
      "Chutti to hogi\n",
      "But m kaam kru hu thodi der\n",
      " Ok\n",
      " Baby kit se, ke kr r\n"
     ]
    }
   ],
   "source": [
    "print(text_data[:99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c24d8fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 29570\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "print(\"Characters:\", total_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ccea8dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: 13422\n"
     ]
    }
   ],
   "source": [
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bbdc7491",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "        # Tokenize the entire text\n",
    "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "\n",
    "\n",
    "def create_dataloader_v1(txt, batch_size=4, max_length=256, \n",
    "                         stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
    "    # Initialize the tokenizer\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    # Create dataset\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "    # Create dataloader\n",
    "    dataloader = DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last, num_workers=0)\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "#with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "#    raw_text = f.read()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d6f2ffea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "#with open(\"train_on_geeta.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "#    raw_text = f.read()\n",
    "with open(\"/home/bioinfo2/Downloads/myfiles/doc/WhatsAppChat.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "encoded_text = tokenizer.encode(raw_text)\n",
    "\n",
    "vocab_size = 50257\n",
    "output_dim = 256\n",
    "context_length = 1024\n",
    "\n",
    "\n",
    "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)\n",
    "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)\n",
    "\n",
    "max_length = 4\n",
    "dataloader = create_dataloader_v1(raw_text, batch_size=8, max_length=max_length, stride=max_length)\n",
    "for batch in dataloader:\n",
    "    x, y = batch\n",
    "    token_embeddings = token_embedding_layer(x)\n",
    "    pos_embeddings = pos_embedding_layer(torch.arange(max_length))\n",
    "    input_embeddings = token_embeddings + pos_embeddings\n",
    "    break\n",
    "\n",
    "    \n",
    "print(input_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4b93926c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from previous_chapters import **create_dataloader_v1**\n",
    "\n",
    "# Train/validation ratio\n",
    "train_ratio = 0.80\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "86b8bd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "\n",
    "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the training loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"increase the `training_ratio`\")\n",
    "\n",
    "if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the validation loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"decrease the `training_ratio`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "877101af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([1, 256]) torch.Size([1, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4f9305c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokens: 10752\n",
      "Validation tokens: 2304\n",
      "All tokens: 13056\n"
     ]
    }
   ],
   "source": [
    "#Another optional check that the token sizes are in the expected ballpark:\n",
    "\n",
    "train_tokens = 0\n",
    "for input_batch, target_batch in train_loader:\n",
    "    train_tokens += input_batch.numel()\n",
    "\n",
    "val_tokens = 0\n",
    "for input_batch, target_batch in val_loader:\n",
    "    val_tokens += input_batch.numel()\n",
    "\n",
    "print(\"Training tokens:\", train_tokens)\n",
    "print(\"Validation tokens:\", val_tokens)\n",
    "print(\"All tokens:\", train_tokens + val_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ef395e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3839e149",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next, we implement a utility function to calculate the cross entropy loss of a given batch In addition, we implement a second utility function to compute the loss for a user-specified number of batches in a data loader\n",
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "85002b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 5.084485349201021\n",
      "Validation loss: 6.853784656524658\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
    "\n",
    "\n",
    "torch.manual_seed(123) # For reproducibility due to the shuffling in the data loader\n",
    "\n",
    "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04bdf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "** Training an LLM **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5d0eac2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally implement the code for training the LLM We focus on a simple training function (if you are interested in augmenting this training function with more advanced techniques, such as learning rate warmup, cosine annealing, and gradient clipping, please refer to Appendix D)\n",
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode      \n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "        # Print a sample text after each epoch\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "        decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "        print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7cc7d7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.347, Val loss 10.015\n",
      "Ep 1 (Step 000005): Train loss 7.732, Val loss 8.570\n",
      "Ep 1 (Step 000010): Train loss 6.492, Val loss 7.500\n",
      "Ep 1 (Step 000015): Train loss 5.623, Val loss 7.088\n",
      "Ep 1 (Step 000020): Train loss 5.361, Val loss 7.047\n",
      "Every effort moves you \n",
      "Ep 2 (Step 000025): Train loss 5.122, Val loss 6.730\n",
      "Ep 2 (Step 000030): Train loss 4.777, Val loss 6.645\n",
      "Ep 2 (Step 000035): Train loss 4.585, Val loss 6.584\n",
      "Ep 2 (Step 000040): Train loss 4.174, Val loss 6.461\n",
      "Every effort moves you Kuch Kuch Kuch kr rhi hu Kuch Kuch Kuch Kuch Kuch Kuch Kuch bhi hu Kuch kr rhi hu \n",
      "Ep 3 (Step 000045): Train loss 3.929, Val loss 6.393\n",
      "Ep 3 (Step 000050): Train loss 3.924, Val loss 6.277\n",
      "Ep 3 (Step 000055): Train loss 3.281, Val loss 6.284\n",
      "Ep 3 (Step 000060): Train loss 3.318, Val loss 6.265\n",
      "Every effort moves you          \n",
      "Ep 4 (Step 000065): Train loss 3.269, Val loss 6.204\n",
      "Ep 4 (Step 000070): Train loss 2.933, Val loss 6.211\n",
      "Ep 4 (Step 000075): Train loss 2.801, Val loss 6.220\n",
      "Ep 4 (Step 000080): Train loss 2.673, Val loss 6.194\n",
      "Every effort moves youhe h   mujhe ho toh rhe h  Mujhejh dekha h Mujhe bhi Mujhe ni kr rhega \n",
      "Ep 5 (Step 000085): Train loss 2.583, Val loss 6.104\n",
      "Ep 5 (Step 000090): Train loss 2.428, Val loss 6.134\n",
      "Ep 5 (Step 000095): Train loss 2.054, Val loss 6.177\n",
      "Ep 5 (Step 000100): Train loss 1.772, Val loss 6.200\n",
      "Every effort moves you...m      Mujhe ho       \n",
      "Ep 6 (Step 000105): Train loss 1.882, Val loss 6.187\n",
      "Ep 6 (Step 000110): Train loss 1.669, Val loss 6.210\n",
      "Ep 6 (Step 000115): Train loss 1.385, Val loss 6.227\n",
      "Ep 6 (Step 000120): Train loss 1.279, Val loss 6.292\n",
      "Ep 6 (Step 000125): Train loss 1.385, Val loss 6.402\n",
      "Every effort moves you...m  Kya krna Kya krna        Mai pecha na choru Bia h Ok G\n",
      "Ep 7 (Step 000130): Train loss 1.021, Val loss 6.335\n",
      "Ep 7 (Step 000135): Train loss 0.919, Val loss 6.324\n",
      "Ep 7 (Step 000140): Train loss 1.007, Val loss 6.340\n",
      "Ep 7 (Step 000145): Train loss 0.816, Val loss 6.441\n",
      "Every effort moves you...m bhi krta hu kr dunga     abhi toh baat krlena  Kyuki Mai pecha na choru  Agr krne sb kru \n",
      "Ep 8 (Step 000150): Train loss 0.729, Val loss 6.514\n",
      "Ep 8 (Step 000155): Train loss 0.626, Val loss 6.508\n",
      "Ep 8 (Step 000160): Train loss 0.619, Val loss 6.570\n",
      "Ep 8 (Step 000165): Train loss 0.583, Val loss 6.591\n",
      "Every effort moves you...mai he janne laga Is bar pass ho jau vhi kre na aya na av Ha Ha    Hmai masti krta hu mai rota nhi\n",
      "Ep 9 (Step 000170): Train loss 0.475, Val loss 6.653\n",
      "Ep 9 (Step 000175): Train loss 0.413, Val loss 6.765\n",
      "Ep 9 (Step 000180): Train loss 0.442, Val loss 6.723\n",
      "Ep 9 (Step 000185): Train loss 0.332, Val loss 6.725\n",
      "Every effort moves you...mne m to rh lega h ? Ya bat soch k mt shod  Kde bhi na rhve   I know  Aazman ka time koni Tym gel pta l\n",
      "Ep 10 (Step 000190): Train loss 0.365, Val loss 6.754\n",
      "Ep 10 (Step 000195): Train loss 0.360, Val loss 6.947\n",
      "Ep 10 (Step 000200): Train loss 0.230, Val loss 6.879\n",
      "Ep 10 (Step 000205): Train loss 0.206, Val loss 6.887\n",
      "Every effort moves you...mne baat kru hmare sath ho rhi hu Class me logo se Sir ni ae h  Ok  Anu  Help Wow Yhi bat meko lgri h   \n"
     ]
    }
   ],
   "source": [
    "#Now, let's train the LLM using the training function defined above:\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "#num_epochs = 100\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0f9e5904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "695fd845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you... ke karu   yhi kitna h aap\n"
     ]
    }
   ],
   "source": [
    "#Modifying the text generation function\n",
    "#The previous two subsections introduced temperature sampling and top-k sampling Let's use these two concepts to modify the generate_simple function we used to generate text via the LLM earlier, creating a new generate function:\n",
    "\n",
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "        # New: Filter logits with top_k sampling\n",
    "        if top_k is not None:\n",
    "            # Keep only top_k values\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float('-inf')).to(logits.device), logits)\n",
    "        # New: Apply temperature scaling\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            # Apply softmax to get probabilities\n",
    "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
    "            # Sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
    "        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
    "            break\n",
    "        # Same as before: append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
    "    return idx\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ec407c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Hi what is life m nhi ki lab kru thha hove bol dlt rice khilaya\n",
      "Jau rdy hone hi bej dung vha pak baat kisi s to le Ava ge\n",
      "Thik h or log sy\n"
     ]
    }
   ],
   "source": [
    "################\n",
    "token_ids = generate(\n",
    "     model=model,\n",
    "     idx=text_to_token_ids(\"Hi what is life\", tokenizer),\n",
    "     max_new_tokens=50,\n",
    "     context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "     top_k=25,\n",
    "     temperature=1.4\n",
    " )\n",
    "\n",
    " \n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7e34da2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and saving model weights in PyTorch\n",
    "\n",
    "#The recommended way in PyTorch is to save the model weights, the so-called state_dict via by applying the torch.save function to the .state_dict() method:\n",
    "\n",
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "\n",
    "#Then we can load the model weights into a new GPTModel model instance as follows:\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(torch.load(\"model.pth\"))\n",
    "model.eval();\n",
    "\n",
    "#It's common to train LLMs with adaptive optimizers like Adam or AdamW instead of regular SGD These adaptive optimizers store additional parameters for each model weight, so it makes sense to save them as well in case we plan to continue the pretraining later:\n",
    "\n",
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    }, \n",
    "    \"model_and_optimizer.pth\"\n",
    ")\n",
    "checkpoint = torch.load(\"model_and_optimizer.pth\")\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0005, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train();\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0282e5f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GPT2Model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[89], line 12\u001b[0m\n\u001b[1;32m      3\u001b[0m model_names \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt2-small (124M)\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenai-community/gpt2\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt2-medium (355M)\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenai-community/gpt2-medium\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt2-large (774M)\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenai-community/gpt2-large\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt2-xl (1558M)\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenai-community/gpt2-xl\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m }\n\u001b[1;32m     10\u001b[0m CHOOSE_MODEL \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt2-small (124M)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 12\u001b[0m gpt_hf \u001b[38;5;241m=\u001b[39m \u001b[43mGPT2Model\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_names[CHOOSE_MODEL], cache_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheckpoints\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m gpt_hf\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Adjusted configuration mapping\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'GPT2Model' is not defined"
     ]
    }
   ],
   "source": [
    "#5.5 Loading pretrained weights from OpenAI\n",
    "\n",
    "model_names = {\n",
    "    \"gpt2-small (124M)\": \"openai-community/gpt2\",\n",
    "    \"gpt2-medium (355M)\": \"openai-community/gpt2-medium\",\n",
    "    \"gpt2-large (774M)\": \"openai-community/gpt2-large\",\n",
    "    \"gpt2-xl (1558M)\": \"openai-community/gpt2-xl\"\n",
    "}\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "\n",
    "gpt_hf = GPT2Model.from_pretrained(model_names[CHOOSE_MODEL], cache_dir=\"checkpoints\")\n",
    "gpt_hf.eval()\n",
    "\n",
    "# Adjusted configuration mapping\n",
    "config_mapping = {\n",
    "    \"gpt2-small (124M)\": \"gpt2-small\",\n",
    "    \"gpt2-medium (355M)\": \"gpt2-medium\",\n",
    "    \"gpt2-large (774M)\": \"gpt2-large\",\n",
    "    \"gpt2-xl (1558M)\": \"gpt2-xl\"\n",
    "}\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,    # Vocabulary size\n",
    "    \"context_length\": 1024, # Context length\n",
    "    \"drop_rate\": 0.0,       # Dropout rate\n",
    "    \"qkv_bias\": True        # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "# Update BASE_CONFIG with the selected model configuration\n",
    "BASE_CONFIG.update(model_configs[config_mapping[CHOOSE_MODEL]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde378fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_check(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def load_weights(gpt, gpt_hf):\n",
    "    d = gpt_hf.state_dict()\n",
    "    gpt.pos_emb.weight = assign_check(gpt.pos_emb.weight, d[\"wpe.weight\"])\n",
    "    gpt.tok_emb.weight = assign_check(gpt.tok_emb.weight, d[\"wte.weight\"])\n",
    "    for b in range(BASE_CONFIG[\"n_layers\"]):\n",
    "        q_w, k_w, v_w = np.split(d[f\"h.{b}.attn.c_attn.weight\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign_check(gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign_check(gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign_check(gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "        q_b, k_b, v_b = np.split(d[f\"h.{b}.attn.c_attn.bias\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign_check(gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign_check(gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign_check(gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign_check(gpt.trf_blocks[b].att.out_proj.weight, d[f\"h.{b}.attn.c_proj.weight\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign_check(gpt.trf_blocks[b].att.out_proj.bias, d[f\"h.{b}.attn.c_proj.bias\"])\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign_check(gpt.trf_blocks[b].ff.layers[0].weight, d[f\"h.{b}.mlp.c_fc.weight\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign_check(gpt.trf_blocks[b].ff.layers[0].bias, d[f\"h.{b}.mlp.c_fc.bias\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign_check(gpt.trf_blocks[b].ff.layers[2].weight, d[f\"h.{b}.mlp.c_proj.weight\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign_check(gpt.trf_blocks[b].ff.layers[2].bias, d[f\"h.{b}.mlp.c_proj.bias\"])\n",
    "        gpt.trf_blocks[b].norm1.scale = assign_check(gpt.trf_blocks[b].norm1.scale, d[f\"h.{b}.ln_1.weight\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign_check(gpt.trf_blocks[b].norm1.shift, d[f\"h.{b}.ln_1.bias\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign_check(gpt.trf_blocks[b].norm2.scale, d[f\"h.{b}.ln_2.weight\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign_check(gpt.trf_blocks[b].norm2.shift, d[f\"h.{b}.ln_2.bias\"])\n",
    "    gpt.final_norm.scale = assign_check(gpt.final_norm.scale, d[f\"ln_f.weight\"])\n",
    "    gpt.final_norm.shift = assign_check(gpt.final_norm.shift, d[f\"ln_f.bias\"])\n",
    "    gpt.out_head.weight = assign_check(gpt.out_head.weight, d[\"wte.weight\"])\n",
    "\n",
    "import torch\n",
    "#from previous_chapters import GPTModel\n",
    "\n",
    "gpt = GPTModel(BASE_CONFIG)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "load_weights(gpt, gpt_hf)\n",
    "gpt.to(device)\n",
    "\n",
    "import tiktoken\n",
    "#from previous_chapters import generate, text_to_token_ids, token_ids_to_text\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"Every effort moves\", tokenizer),\n",
    "    max_new_tokens=30,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    "    top_k=1,\n",
    "    temperature=1.0\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c74b3c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
